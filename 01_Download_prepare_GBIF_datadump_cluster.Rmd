---
title: "Download and prepare whole GBIF data on the cluster"
---

1 – Go to GBIF webpage, select the download and copy the IPA. 
Ex: https://api.gbif.org/v1/occurrence/download/request/0329580-210914110416597.zip

save DOI: GBIF.org (01 June 2022) GBIF Occurrence Download https://doi.org/10.15468/dl.3c2mmc 

2 – On PuTTY terminal, go to the folder where the data shall be saved, and use the command: 

```{bash}
wget https://api.gbif.org/v1/occurrence/download/request/0329580-210914110416597.zip
```

3 – Once the data is downloaded, unzip it

```{bash}
unzip 0329580-210914110416597.zip
```


4 – The file will come in .txt separated by tab. To make it easier and lighter to read, separate the data by thematic fields. Than split each thematic field file row-wise, keeping 1 billion records at a time. That is done manually, and it is necessary to check the number or rows.

###### include the database in order to be able to cite properly
###### but maybe I'll cite all GBIF data, lets see

##### include presence or absence collumn VERY IMPORTANT!!!

```{bash}
#Set wd to save thematic fields
cd Thematic_fields

#Species

#select the column containing GBIF ID and the other(s) wanted 
cut -f1,1,240 ../occurrence.txt > gbifID_speciesName.txt

#after doing the first thematic selection, count the rows
wc -l gbifID_speciesName.txt   ### 2,203,539,571 rows  2203539571

#select first 1 billion rows (1 more row because head counts)
head -n 1000000001 gbifID_speciesName.txt > gbifID_speciesName_1.txt
#select second 1 billion rows
head -n 2000000001 gbifID_speciesName.txt | tail -n 1000000000 > gbifID_speciesName_2.txt
#select the last rows (203,539,571)
head -n 2203539571 gbifID_speciesName.txt | tail -n 203539571 > gbifID_speciesName_3.txt

#### Repeate the steps for all desired thematic fields

#Date
cut -f1,1,107,108,109 ../occurrence.txt > gbifID_date.txt

head -n 1000000001 gbifID_date.txt > gbifID_date_1.txt

head -n 2000000001 gbifID_date.txt | tail -n 1000000000 > gbifID_date_2.txt

head -n 2203539571 gbifID_date.txt | tail -n 203539571 > gbifID_date_3.txt


#Coordinates
cut -f1,1,138,139 ../occurrence.txt > gbifID_coordinates.txt 

head -n 1000000001 gbifID_coordinates.txt > gbifID_coordinates_1.txt

head -n 2000000001 gbifID_coordinates.txt | tail -n 1000000000 > gbifID_coordinates_2.txt

head -n 2203539571 gbifID_coordinates.txt | tail -n 203539571 > gbifID_coordinates_3.txt


#Basis of record
cut -f1,1,64 ../occurrence.txt > gbifID_basisOfRecord.txt

head -n 1000000001 gbifID_basisOfRecord.txt > gbifID_basisOfRecord_1.txt

head -n 2000000001 gbifID_basisOfRecord.txt | tail -n 1000000000 > gbifID_basisOfRecord_2.txt

head -n 2203539571 gbifID_basisOfRecord.txt | tail -n 203539571 > gbifID_basisOfRecord_3.txt


#Establishment means
cut -f1,1,80 ../occurrence.txt > gbifID_establishmentMeans.txt

head -n 1000000001 gbifID_establishmentMeans.txt > gbifID_establishmentMeans_1.txt

head -n 2000000001 gbifID_establishmentMeans.txt | tail -n 1000000000 > gbifID_establishmentMeans_2.txt

head -n 2203539571 gbifID_establishmentMeans.txt | tail -n 203539571 > gbifID_establishmentMeans_3.txt


#Occurrence status
cut -f1,1,84 ../occurrence.txt > gbifID_occurrenceStatus.txt

head -n 1000000001 gbifID_occurrenceStatus.txt > gbifID_occurrenceStatus_1.txt

head -n 2000000001 gbifID_occurrenceStatus.txt | tail -n 1000000000 > gbifID_occurrenceStatus_2.txt

head -n 2203539571 gbifID_occurrenceStatus.txt | tail -n 203539571 > gbifID_occurrenceStatus_3.txt


#Occurrence status
cut -f1,1,84 ../occurrence.txt > gbifID_occurrenceStatus.txt

head -n 1000000001 gbifID_occurrenceStatus.txt > gbifID_occurrenceStatus_1.txt

head -n 2000000001 gbifID_occurrenceStatus.txt | tail -n 1000000000 > gbifID_occurrenceStatus_2.txt

head -n 2203539571 gbifID_occurrenceStatus.txt | tail -n 203539571 > gbifID_occurrenceStatus_3.txt


#Dataset ID
cut -f1,1,59 ../occurrence.txt > gbifID_datasetID.txt

head -n 1000000001 gbifID_datasetID.txt > gbifID_datasetID_1.txt

head -n 2000000001 gbifID_datasetID.txt | tail -n 1000000000 > gbifID_datasetID_2.txt

head -n 2203539571 gbifID_datasetID.txt | tail -n 203539571 > gbifID_datasetID_3.txt



#####


cut -f1,1,40,107,108,109 ../occurrence.txt | head

cut -f1,1,181,182,183  ../occurrence.txt | head



###### dataset ID col 59


modified (col 40) could be the date of entry...
lastInterpreted ?

datasetID 
occurrenceStatus


```

Now we can work with R! Create a files relating species names to species unique IDs and another one relating gbifIDs to species names IDs. Repeat the process to each thematic field wanted.

RUN INDIVIDUAL SCRIPTS ON THE CLUSTER BY SUBMITTING JOBS

Save scripts in "Scripts_to_run_jobs" folder in the cluster to request the jobs. Each R script needs a corresponding bash script to submit the job.



